\section{Einleitung}

Diese Bachelorarbeit entsteht in Zusammenarbeit mit der Pixelhouse GmbH. Diese betreibt seit ca. 10 Jahren die Webseite Chefkoch.de, Europas größtes Kochportal. Neben der Vermarktung der Webseite und der Betreuung der Community wird von den Mitarbeitern vor allem auch die softwaretechnische Entwicklung der Plattform und das Hosting durchgeführt \citep[Vgl.][]{pixelhouse14}.

Wie auch andere Firmen, versucht die Pixelhouse GmbH die Entwicklung der Plattform mit Qualitätsicherungsmaßnahmen zu verbessern. Ein gängiges Problem ist hierbei das Bereitstellen von Testumgebungen.

Der hohe Zeitaufwand für das Aufsetzen neuer Testumgebungen und das Durchführen der Systemtests widersprechen schon lange etablierten Softwareentwicklungsmethodiken wie Continuous Integration und Continuous Delivery. Diese zielen darauf ab, kurze Feedbackschleifen für Entwickler und Produktmanager zu ermöglichen, indem sich neue Versionen der Software kurzfristig mit denen anderer Entwickler integriert lassen und ebenso kurzfristig in Produktion genommen werden können, um so auch Feedback von echten Benutzern zu erhalten.

Die Tatsache, dass sich bestimmte Infrastrukturkomponenten gar nicht testen lassen und dass die Zusammenarbeit zwischen Entwicklern und Betrieb hier wenig effizient möglich ist, werden von der Wissenschaft heute bereits mit der DevOps Bewegung beantwortet. Ziel dieser Bewegung ist es, die Konfiguration der Infrastruktur genau wie den Quellcode der Anwendung unter Versionskontrolle zu stellen und ihre Installation und Verwaltung vollständig zu automatisieren.

Die beiden Bücher "`Continous Integration"' \citep{DuvMatAnd07} und "`Continous Delivery"' \citep{HumFar10}, die diese Themen behandeln, gehören zu den Standardwerken der heutigen Literatur zur Softwareentiwcklung.

\subsection{Problemstellung}

Die Webseite Chefkoch.de basiert auf einer seit Beginn des Projektes stetig wachsenden PHP-Anwendung. Da im Ökosystem der Programmiersprache PHP lange Zeit keine guten Werkzeuge zur Verwaltung von Paketen und Abhängigkeiten existierten, besteht die Anwendung nur aus einigen wenigen, eher monolithischen Komponenten. Diese enthalten mitunter auch kopierten Programmcode.

Aufgrund des großen Erfolgs der Website Chefkoch.de ist ihre auf Linux/Ubuntu-Systemen basierende Infrastruktur mit den Jahren sehr komplex geworden, um die hohe Last von mehreren Millionen Besuchern täglich bedienen zu können. So werden Loadbalancer, mehrere Application-Server und diverse Persistenz-Dienste wie SQL-Datenbanken und Key-Value-Stores eingesetzt.

Der Wartungsaufwand für bestehenden Programmcode und der Entwicklungsaufwand für neue Funktionen sind aufgrund der großen, monolithischen Komponenten der Anwendung und der hohen Komplexität ihrer Infrastruktur sehr hoch. Die Herausforderung für das aktuelle Entwicklungsteam besteht deshalb nicht nur darin, das Alltagsgeschäft und die Umsetzung neuer Produktfunktionen voranzutreiben, sondern auch darin, grundlegende Modernisierungen und Umstrukturierungen am System vorzunehmen.

Um bei diesen grundlegenden Arbeiten möglichst wenig Fehler und Systemausfälle zu provozieren, ist es Vorgabe des Managements, bestehende und neue Funktionen über automatisierte Tests abzusichern. Gerade bei bestehenden Funktionen kommen hierbei oft nur Systemtests in Frage, da die zugrundeliegende Software wenig modular aufgebaut ist und so nur selten Unit- oder Integrationstests sinnvoll möglich sind. Die Systemtests werden dabei mit Hilfe des Testtools Behat implementiert, das die Webdriver-Schnittstelle dazu verwendet, echte Webbrowsern über die Seite laufen zu lassen, um die benötigten Funktionen abzutesten.

Das größte Problem mit dieser Art von Systemtest ist, dass die Fernsteuerung von Webbrowsern zum Beispiel im Vergleich zu einfachen Unittests sehr langsam ist und die aktuell bereits existierenden Tests schon mehrere Stunden zur Durchführung benötigen. Dies bedeutet, dass man nach fertiger Implementierung einer neuen Funktion oder der Modernisierung einer bestehenden Komponente sehr lange auf das Testergebnis warten muss und so Zeit vergeht, bis sich die Änderung sicher in den Hauptentzwicklungszweig integrieren oder in Produktion nehmen lässt.

Eine mögliche Lösung hierfür wäre es, möglichst viele Testumgebungen anzubieten, um das Ausführen der automatischen Systemtests möglichst oft parallelisieren zu können oder auch einfach mehrere gleichzeitige manuelle Abnahmen durch das Produktmanagement zu unterstützen.

Stand heute ist es allerdings nur schwer möglich, solche getrennten Testumgebungen aufzusetzen. Die Pixelhouse GmbH besitzt hierfür zwei Server, auf denen mehrere Versionen der Anwendung parallel installiert werden können. Einer der Server ist dabei nur intern erreichbar und steht somit vor allem für interne beziehungsweise automatische Tests zur Verfügung. Der zweite Server ist öffentlich erreichbar und kann somit auch für echte Benutzertests verwendet werden. Die einzelnen Testumgebungen können dabei unterschiedliche Versionen der Anwendung verwenden. Sämtliche Bestandteile der  Infrastruktur wie zum Beispiel Loadbalancer und Datenbanken werden allerdings nur einmal auf den beiden Servern vorgehalten und somit von allen Testumgebungen gleichermaßen verwendet.

So kommt es bei der Ausführung von automatischen oder manuellen Systemtests sehr leicht vor, dass Testdaten fehlen oder inkonsistent sind, weil sie bereits von einer anderen Umgebung gelöscht oder verändert wurden. Auch lassen sich Konfigurationsänderungen an diesen Infrasktruktur-Komponenten heute auf diesen beiden Servern gar nicht testen, da entsprechende Änderungen sich immer auf alle Testumgebungen gleichzeitig auswirken.

Eine Lösung zur Bereitstellung weiterer isolierter Testumgebungen wären natürlich die Beschaffung und Einrichtung weiterer Hardwareinstanzen. Das wäre aber natürlich mit sehr viel Aufwand und Kosten verbunden. Die Idee der Pixelhouse GmbH ist es nun, hier mit Hilfe von Virtualisierung Lösungen zu erarbeiten.

\subsection{Ziel}

Ziel dieser Bachelorarbeit ist es zu untersuchen, ob man mit Hilfe von Virtualisierungstechniken eine Lösung für das oben beschriebene Problem schaffen kann. Mit dieser Lösung soll nicht nur die Anwendung sondern auch deren Infrastruktur in einem konkreten Zustand nachgehalten und effizient aufgesetzt werden können, um so einfach und beliebig oft Testumgebungen anbieten zu können. Neben der konzeptionellen Arbeit soll auch eine prototypische Umsetzung und eine Bewertung erfolgen.

\subsection{Vorgehensweise}

Diese Arbeit gibt im zweiten Kapitel "`Grundlagen und Ansätze"' zunächst einen Überblick über die für die Problemstellung relevanten Virtualisierungsansätze. Im darauf folgenden Kapitel "`Konzeption"' sollen dann zwei Ansätze ausgewählt und jeweils ein Konzept zur Lösung der Problemstellung erarbeitet werden. Im anschließenden Kapitel "`Implementierung"' werden die Ergebnisse der prototypischen Umsetzung - vor allem deren Probleme und Besonderheiten - beschrieben. Im vorletzten Kapitel "`Evaluation"' soll eine objektive Bewertung der beiden Umsetzungen erfolgen. Das letzte Kapitel "`Fazit"' fasst die Ergebnisse der Arbeit zusammen und gibt einen Ausblick auf mögliche weitere Schritte.

